{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset from Hugging Face\n",
    "- The original LLaVA repo asks us to load the MME data from the [Github repo](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation)\n",
    "- But we are instead using [lmms-lab/MME](https://huggingface.co/datasets/lmms-lab/MME)\n",
    "- This notebook explains the code behind the evaluation for the new script mme.sh\n",
    "- You can also run it to eval the model on Maya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "# Load the MME dataset from Hugging Face\n",
    "# mme_dataset = load_dataset(\"lmms-lab/MME\")\n",
    "save_dir = \"../../../playground/data/eval/MME\"\n",
    "\n",
    "# # Save the dataset locally to the specified directory\n",
    "# mme_dataset.save_to_disk(save_dir)\n",
    "\n",
    "# If already downloaded uncomment this and comment the downloading code\n",
    "mme_dataset = load_from_disk(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis\n",
    "### Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Structure\")\n",
    "print(mme_dataset)\n",
    "print()\n",
    "\n",
    "print(\"Data Row\")\n",
    "print(mme_dataset['test'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many types of image extensions \n",
    "- Note that we only have one split, 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mme_df = pd.DataFrame(mme_dataset['test'])\n",
    "#\n",
    "mme_df['image_name'] = mme_df['question_id'].apply(lambda x: x.split('/')[-1])\n",
    "mme_df['extension'] = mme_df['image_name'].apply(lambda x: x.split('.')[-1])\n",
    "\n",
    "# Get a list of unique image extensions\n",
    "unique_extensions = mme_df['extension'].unique()\n",
    "\n",
    "# Display the unique extensions\n",
    "print(f\"Unique extensions in test split: {unique_extensions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between LLaVA MME jsonl file and Hugging Face MME\n",
    "- The Hugging Face MME file stores images in `category/image.png`\n",
    "- But the LLaVA repo's `llava_mme.json` expects images to be stored in `category/image/image.png` for categories `artwork`, `celebrity`, `landmark`, `scene`, and `posters`.\n",
    "- Later in the image-saving code, we need to account for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"../../../playground/data/eval/MME/llava_mme.jsonl\", 'r') as f:\n",
    "    jsonl_data = [json.loads(line) for line in f] \n",
    "\n",
    "mme_jsonl_df = pd.DataFrame(jsonl_data)\n",
    "\n",
    "# Filter rows where 'question_id' starts with 'scene'\n",
    "mme_df[mme_df['question_id'].str.startswith('scene')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mme_jsonl_df\n",
    "mme_jsonl_df[mme_jsonl_df['question_id'].str.startswith('scene')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images to folder\n",
    "- Instead of taking MME images from the GitHub, we use `lmms-lab/MME` on Hugging Face instead.\n",
    "- We could just use HF to eval the model, however, we want to stay to the llava structure/scripts as much as possible\n",
    "- Therefore, we will stick to using the original files as part of [eval.zip](https://drive.google.com/file/d/1atZSBBrAX54yYpxtVVW33zFvcnaHeFPy/view?usp=sharing), and the original structure from the LLaVA repo:\n",
    "    - `./playground/data/eval/MME/llava_mme.jsonl` as our questions file\n",
    "    - `./playground/data/eval/MME/MME_Benchmark_release_version` is our images folder\n",
    "    - `./playground/data/eval/MME/convert_answer_to_mme.py` \n",
    "- We extract images to `./playground/data/eval/MME/MME_Benchmark_release_version` \n",
    "- And then we run the original `model_vqa_loader.py` and the `calculation.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run to clear loaded images and questions in case of an error\n",
    "# ! rm -rf  ../../../playground/data/eval/MME/MME_Benchmark_release_version/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16895054fc644a3a47c4b6eee2d6f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "image_save_base_path = \"../../../playground/data/eval/MME/MME_Benchmark_release_version\"\n",
    "\n",
    "# ensure the base path exists\n",
    "os.makedirs(image_save_base_path, exist_ok=True)\n",
    "\n",
    "# categories that should have the extra subdirectory for images\n",
    "special_categories = [\"artwork\", \"celebrity\", \"landmark\", \"scene\", \"posters\"]\n",
    "\n",
    "# save an image to the specified directory\n",
    "def save_images(example):\n",
    "    image = example['image']\n",
    "    image_subdir = example['question_id']  # category/image.png\n",
    "    category = image_subdir.split('/')[0]  # extract the category (first part of question_id)\n",
    "    file_name = os.path.basename(image_subdir)  # extract the file name (including extension)\n",
    "\n",
    "    # get the image extension (e.g., \".png\", \".jpg\")\n",
    "    _, extension = os.path.splitext(file_name)\n",
    "\n",
    "    # check if the category is one of the special ones that needs an extra 'images' folder\n",
    "    if category in special_categories:\n",
    "        # save in the category/images/ structure (e.g., artwork/images/16006.jpg)\n",
    "        full_save_dir = os.path.join(image_save_base_path, category, \"images\")\n",
    "    else:\n",
    "        # save in the usual category/image.png structure (e.g., code_reasoning/0012.png)\n",
    "        full_save_dir = os.path.join(image_save_base_path, category)\n",
    "\n",
    "    # create the subdirectory if it doesn't exist\n",
    "    os.makedirs(full_save_dir, exist_ok=True)\n",
    "\n",
    "    # create the full image save path\n",
    "    image_save_path = os.path.join(full_save_dir, file_name)\n",
    "\n",
    "    # save the image to the specified path in the correct format\n",
    "    if extension.lower() == \".jpg\" or extension.lower() == \".jpeg\":\n",
    "        image.save(image_save_path, format=\"JPEG\")\n",
    "    elif extension.lower() == \".png\":\n",
    "        image.save(image_save_path, format=\"PNG\")\n",
    "    else:\n",
    "        # handle other formats or default to PNG (though this shouldn't happen!)\n",
    "        image.save(image_save_path, format=\"PNG\")\n",
    "\n",
    "    return {'image_save_path': image_save_path}\n",
    "\n",
    "# apply this function to the dataset (for instance, on the 'test' split)\n",
    "_ = mme_dataset['test'].map(save_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Y/N Answers to Folder\n",
    "- This is needed by `convert_answer_to_mme.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to delete all txt files\n",
    "# ! find ../../../playground/data/eval/MME/MME_Benchmark_release_version -type f -name \"*.txt\" -delete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "answer_save_base_path = \"../../../playground/data/eval/MME/MME_Benchmark_release_version\"\n",
    "\n",
    "# categories that should have the extra subdirectory for Y/N answers\n",
    "special_categories = [\"artwork\", \"celebrity\", \"landmark\", \"scene\", \"posters\"]\n",
    "\n",
    "# save Y/N answers to the specified directory\n",
    "def save_answer(example):\n",
    "    question_id = example['question_id']  # category/image.png\n",
    "    question = example['question']\n",
    "    answer = example['answer']  \n",
    "    \n",
    "    category = question_id.split('/')[0]  # extract category (first part of question_id)\n",
    "    image_name = os.path.basename(question_id)  # extract the file name (including extension)\n",
    "    image_basename = os.path.splitext(image_name)[0]  # remove the extension for the text file\n",
    "\n",
    "    # determine where to save the Y/N answer file\n",
    "    if category in special_categories:\n",
    "        # special categories will have a \"questions_answers_YN\" subdirectory\n",
    "        full_save_dir = os.path.join(answer_save_base_path, category, \"questions_answers_YN\")\n",
    "    else:\n",
    "        # non-special categories will save directly in the category folder\n",
    "        full_save_dir = os.path.join(answer_save_base_path, category)\n",
    "\n",
    "    # create the subdirectory if it doesn't exist\n",
    "    os.makedirs(full_save_dir, exist_ok=True)\n",
    "\n",
    "    # define the full path for saving the answer file\n",
    "    answer_save_path = os.path.join(full_save_dir, f\"{image_basename}.txt\")\n",
    "\n",
    "    # append the question and answer into the text file (use 'a' mode to append)\n",
    "    with open(answer_save_path, 'a') as answer_file:\n",
    "        answer_file.write(f\"{question}\\t{answer}\\n\")\n",
    "\n",
    "    return {'answer_save_path': answer_save_path}\n",
    "\n",
    "\n",
    "_ = mme_dataset['test'].map(save_answer)\n",
    "\n",
    "print(\"Y/N answers have been processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "project_root = \"../../../\"  # Path to the root of your project\n",
    "\n",
    "# Set the current working directory to the project root and run the scripts\n",
    "# subprocess.run([\n",
    "#     \"python\", \"-m\", \"llava.eval.model_vqa_loader\",\n",
    "#     \"--model-path\", \"nahidalam/maya_full_ft\",\n",
    "#     \"--model-base\", \"CohereForAI/aya-23-8B\",\n",
    "#     \"--question-file\", \"./playground/data/eval/MME/llava_mme.jsonl\",\n",
    "#     \"--image-folder\", \"./playground/data/eval/MME/MME_Benchmark_release_version\",\n",
    "#     \"--answers-file\", \"./playground/data/eval/MME/answers/llava-v1.5-13b.jsonl\",\n",
    "#     \"--temperature\", \"0\",\n",
    "#     \"--conv-mode\", \"aya\",\n",
    "# ], cwd=project_root)\n",
    "\n",
    "# Similarly, for the other subprocess calls\n",
    "# subprocess.run([\n",
    "#     \"python\", \"convert_answer_to_mme.py\", \n",
    "#     \"--experiment\", \"llava-v1.5-13b\"], \n",
    "#     cwd=os.path.join(project_root, \"playground/data/eval/MME\"))\n",
    "\n",
    "subprocess.run([\n",
    "    \"python\", \"calculation.py\", \n",
    "    \"--results_dir\", \"answers/llava-v1.5-13b\"], \n",
    "    cwd=os.path.join(project_root, \"playground/data/eval/MME/eval_tool\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
